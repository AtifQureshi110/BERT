{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtifQureshi110/BERT/blob/main/sapm_and_ham_locked.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56cEvlZGCqIx"
      },
      "source": [
        "### Libraries Installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHNgFUugLpCV",
        "outputId": "be1cb12e-7d3c-405a-acb0-a17a7ca479c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip  install transformers==4.22.1 -q\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LjX6uRPLrr4",
        "outputId": "42fc22f6-170c-4b07-ee3f-4f3d66577276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.10 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (3.9.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (23.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (0.33.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Requirement already satisfied: tensorflow_probability==0.12.2 in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.23.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.1.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow==2.10\n",
        "!pip install keras\n",
        "!pip install tensorflow_probability==0.12.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUcv5rOQDHKr"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57jyVMnxLw-D",
        "outputId": "c799378f-a503-43eb-aaa9-afb71aead8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n",
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx2Vglw6IKrQ"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, TextClassificationPipeline\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NltdKTMPDXTF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK2FqSDaD0Yp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixt5qEORD44u"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTfFtRQREDc9"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained DistilBERT model for sequence classification\n",
        "from transformers import TFTrainingArguments, TFDistilBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGDr97y6q61A",
        "outputId": "ce5cdd84-e970-4421-b2cc-01cea702cb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGzY5SOHDOWd"
      },
      "source": [
        "### Load tokenizer, model, and pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKrwsZa4IXrP",
        "outputId": "44178bdb-6581-44a6-f9d4-697485483b29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load tokenizer, model, and pipeline\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=0)  # Specify device if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LoMZk_ZDebj"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuFSoTCIM8O2"
      },
      "outputs": [],
      "source": [
        "# data from https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv\n",
        "file_path=\"/content/drive/MyDrive/BERT/spam_ham_Bert_binary/spam.csv\"\n",
        "df = pd.read_csv(file_path,encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVXqVFf4M86x"
      },
      "outputs": [],
      "source": [
        "df.drop(['Unnamed: 2',\t'Unnamed: 3',\t'Unnamed: 4'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPIHOJgSQzyA"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'v1':'type','v2':'text'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se5lI2l4M9_m"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df['type_encoded'] = label_encoder.fit_transform(df['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK0mDRnnRklu"
      },
      "outputs": [],
      "source": [
        "df[\"text_word_count\"] = df['text'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55rRw8J1QqSj",
        "outputId": "d25186ea-7ac8-4f55-f29d-d580a9ba4f15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8dce0f7b-eab0-4d08-8823-bad42601c566\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>type_encoded</th>\n",
              "      <th>text_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dce0f7b-eab0-4d08-8823-bad42601c566')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dce0f7b-eab0-4d08-8823-bad42601c566 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dce0f7b-eab0-4d08-8823-bad42601c566');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d83dd886-9de7-4807-a87b-ecfbe39b4fbb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d83dd886-9de7-4807-a87b-ecfbe39b4fbb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d83dd886-9de7-4807-a87b-ecfbe39b4fbb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      type                                               text  type_encoded  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...             0   \n",
              "1      ham                      Ok lar... Joking wif u oni...             0   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...             1   \n",
              "3      ham  U dun say so early hor... U c already then say...             0   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...             0   \n",
              "...    ...                                                ...           ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...             1   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?             0   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...             0   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...             0   \n",
              "5571   ham                         Rofl. Its true to its name             0   \n",
              "\n",
              "      text_word_count  \n",
              "0                  20  \n",
              "1                   6  \n",
              "2                  28  \n",
              "3                  11  \n",
              "4                  13  \n",
              "...               ...  \n",
              "5567               30  \n",
              "5568                8  \n",
              "5569               10  \n",
              "5570               26  \n",
              "5571                6  \n",
              "\n",
              "[5572 rows x 4 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3CP78FADjpb"
      },
      "source": [
        "### Selecting Target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUT6Y8uQR8r_"
      },
      "outputs": [],
      "source": [
        "X = df['text'].to_list()\n",
        "y = df['type_encoded'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCNRaHXWSa5J"
      },
      "outputs": [],
      "source": [
        "#Train Test SPlit\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cqp6WGfz3L4",
        "outputId": "2beba4e0-83dc-4cb2-fbc0-bcb624645c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train :4457\n",
            "y_train: 1115\n",
            "X_test:4457\n",
            "y_test: 1115\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train :{len(X_train)}\\ny_train: {len(y_train)}\\nX_test:{len(X_test)}\\ny_test: {len(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFDdauIWEL9V"
      },
      "source": [
        "### Preprocess your text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHTVc8XPS4jO"
      },
      "outputs": [],
      "source": [
        "# Preprocess your text data\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True, return_tensors='tf')\n",
        "test_encodings = tokenizer(y_train, truncation=True, padding=True, return_tensors='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuJizXtTTijD"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(X_test)\n",
        "test_labels = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDXFdmKiETKL"
      },
      "source": [
        "### Create TensorFlow datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvDSU0XuTte0"
      },
      "outputs": [],
      "source": [
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDX8V9WEWqM"
      },
      "source": [
        "### Define and configure training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CizzqNeEUq9g"
      },
      "outputs": [],
      "source": [
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_steps=500,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z58o2OYWuRE",
        "outputId": "80470ee3-f17e-475f-af77-315d7951929e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_99']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "trainer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMv9tcTcXqle"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbU3iqVVYPDh",
        "outputId": "9929be59-5f1e-4152-fd82-c1d6137aa74c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_119']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Create your model within the distribution strategy scope\n",
        "with training_args.strategy.scope():\n",
        "    trainer_model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTB9pswRY6Dl",
        "outputId": "c14be23e-8993-4370-c4f0-8b89d55ea78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "558/558 [==============================] - 127s 205ms/step - loss: 0.0764 - accuracy: 0.9773\n",
            "Epoch 2/3\n",
            "558/558 [==============================] - 115s 207ms/step - loss: 0.0279 - accuracy: 0.9933\n",
            "Epoch 3/3\n",
            "558/558 [==============================] - 116s 208ms/step - loss: 0.0155 - accuracy: 0.9966\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0294787070>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_model.fit(train_dataset.batch(training_args.per_device_train_batch_size), epochs=training_args.num_train_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VZE49ElXZKG7",
        "outputId": "949aca66-c777-4501-b07f-bd963d8e3d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 9s 354ms/step - loss: 0.0308 - accuracy: 0.9937\n",
            "Evaluation results: [0.030838605016469955, 0.9937219619750977]\n"
          ]
        }
      ],
      "source": [
        "results = trainer_model.evaluate(test_dataset.batch(training_args.per_device_eval_batch_size))\n",
        "print(\"Evaluation results:\", results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uyGBtuPls4f7",
        "outputId": "ef5e038f-ab49-41dc-bfa5-4b01728652af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 8s 354ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput(loss=None, logits=array([[ 4.51577  , -3.826219 ],\n",
              "       [ 4.529523 , -3.8304043],\n",
              "       [ 4.5129156, -3.8147051],\n",
              "       ...,\n",
              "       [ 4.531191 , -3.8368244],\n",
              "       [ 4.5304565, -3.8404036],\n",
              "       [ 3.3770819, -2.8276567]], dtype=float32), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict labels for the test dataset\n",
        "predictions = trainer_model.predict(test_dataset.batch(training_args.per_device_eval_batch_size))\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5W95FXPOtEML",
        "outputId": "7c7eaaec-3424-48f9-fade-d5cd35fbb16b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput(loss=None, logits=array([[ 4.51577  , -3.826219 ],\n",
              "       [ 4.529523 , -3.8304043],\n",
              "       [ 4.5129156, -3.8147051],\n",
              "       ...,\n",
              "       [ 4.531191 , -3.8368244],\n",
              "       [ 4.5304565, -3.8404036],\n",
              "       [ 3.3770819, -2.8276567]], dtype=float32), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXJMwbRl_Ubs"
      },
      "outputs": [],
      "source": [
        "# Define a threshold value for converting scores to labels\n",
        "threshold = 0.5  # Adjust this threshold as needed\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "df['predicted_label'] = np.where(predictions.logits > threshold, 1, 0)\n",
        "\n",
        "# Display the DataFrame with predicted labels\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16SYL3VutAaH"
      },
      "outputs": [],
      "source": [
        "from transformers import TFTrainer, TFTrainingArguments\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the predicted labels from the predictions\n",
        "#predicted_labels = predictions.predictions.argmax(axis=1).numpy()\n",
        "predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()\n",
        "\n",
        "# Get the actual labels from the test dataset\n",
        "actual_labels = [label.numpy() for _, label in test_dataset]\n",
        "\n",
        "# Compare the predicted labels with the actual labels\n",
        "for i in range(len(predicted_labels)):\n",
        "    print(f\"Example {i + 1} - Actual: {actual_labels[i]}, Predicted: {predicted_labels[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zz_BPiAsn8E"
      },
      "outputs": [],
      "source": [
        "# Fit the model to the training dataset\n",
        "trainer_model.fit(train_dataset.batch(training_args.per_device_train_batch_size), epochs=training_args.num_train_epochs)\n",
        "\n",
        "# Predict labels for the test dataset\n",
        "predictions = trainer_model.predict(test_dataset.batch(training_args.per_device_eval_batch_size))\n",
        "\n",
        "# Get the predicted labels and logits from the predictions\n",
        "predicted_labels = tf.argmax(predictions.predictions, axis=1).numpy()\n",
        "predicted_logits = predictions.predictions.numpy()\n",
        "\n",
        "# Get the actual labels from the test dataset\n",
        "actual_labels = [label.numpy() for _, label in test_dataset]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjhx9mqPEhRf"
      },
      "source": [
        "### Saving & Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HjPHC32s3Jky"
      },
      "outputs": [],
      "source": [
        "#Saving & Loading the model\n",
        "save_directory = \"/saved_models\"\n",
        "model.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyOJLvl-3SRF",
        "outputId": "5759e7ac-736f-4ee8-9b59-acefc05625dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/saved_models/tokenizer_config.json',\n",
              " '/saved_models/special_tokens_map.json',\n",
              " '/saved_models/vocab.txt',\n",
              " '/saved_models/added_tokens.json')"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42YzKmQAEnKN"
      },
      "source": [
        "### Loading Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4uYsum93Yz-",
        "outputId": "5e033865-b1ef-46e5-e14f-ca64a27b74d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at /saved_models were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at /saved_models and are newly initialized: ['dropout_99']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#Loading Pre-Trained Model\n",
        "tokenizer_fine_tuned = DistilBertTokenizer.from_pretrained(save_directory)\n",
        "model_fine_tuned = TFDistilBertForSequenceClassification.from_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7VwFTID3mnA"
      },
      "outputs": [],
      "source": [
        "y_train = y_train[2]\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnVwv5h54BNF",
        "outputId": "5afeccbc-6ce7-476f-f04d-1c78993a3f5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_input = tokenizer_fine_tuned.encode(\n",
        "    y_train,\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "    return_tensors = 'tf'\n",
        ")\n",
        "\n",
        "output = model_fine_tuned(predict_input)[0]\n",
        "\n",
        "prediction_value = tf.argmax(output, axis = 1).numpy()[0]\n",
        "\n",
        "prediction_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkMXmNc6xRUM"
      },
      "source": [
        "#sbcb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuUByqLgfr66",
        "outputId": "d42e74ab-b5bb-4f11-96f6-6beb8e8e5f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 11s 56ms/step\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = trainer_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvOfLYHAgZTE",
        "outputId": "905e9e19-12e3-449f-ca52-640fa24c12aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TFSequenceClassifierOutput(loss=None, logits=array([[-2.8904889 ,  2.827261  ],\n",
              "       [-2.8766267 ,  2.8100615 ],\n",
              "       [-2.885503  ,  2.821956  ],\n",
              "       [-2.9026833 ,  2.8438442 ],\n",
              "       [-2.8899822 ,  2.826699  ],\n",
              "       [-2.8964198 ,  2.8352733 ],\n",
              "       [-2.898803  ,  2.83865   ],\n",
              "       [-2.8891773 ,  2.8264182 ],\n",
              "       [-2.8751347 ,  2.8076615 ],\n",
              "       [-2.8904862 ,  2.8290937 ],\n",
              "       [-2.8811347 ,  2.8143876 ],\n",
              "       [-2.8924742 ,  2.8285248 ],\n",
              "       [-2.8819401 ,  2.8174126 ],\n",
              "       [-2.894182  ,  2.8320987 ],\n",
              "       [-2.8779342 ,  2.812503  ],\n",
              "       [-2.8864    ,  2.8240535 ],\n",
              "       [-2.8934538 ,  2.8309734 ],\n",
              "       [-2.8851924 ,  2.8207319 ],\n",
              "       [-2.8847926 ,  2.821268  ],\n",
              "       [-2.8915598 ,  2.8276443 ],\n",
              "       [-2.8867402 ,  2.8219538 ],\n",
              "       [-2.8854513 ,  2.8216171 ],\n",
              "       [-2.8933342 ,  2.8309875 ],\n",
              "       [-2.8744612 ,  2.808836  ],\n",
              "       [-2.8953183 ,  2.8346622 ],\n",
              "       [-2.8803852 ,  2.815894  ],\n",
              "       [-2.8823717 ,  2.816961  ],\n",
              "       [-2.8835106 ,  2.8190587 ],\n",
              "       [-2.886387  ,  2.822618  ],\n",
              "       [-2.8866065 ,  2.822132  ],\n",
              "       [-2.885135  ,  2.8214178 ],\n",
              "       [-2.8894818 ,  2.8262837 ],\n",
              "       [-2.883305  ,  2.8189838 ],\n",
              "       [-2.89153   ,  2.8290384 ],\n",
              "       [-2.8801644 ,  2.8142426 ],\n",
              "       [-2.8776276 ,  2.8124063 ],\n",
              "       [-2.8884938 ,  2.8254416 ],\n",
              "       [-2.892573  ,  2.8304696 ],\n",
              "       [-2.880323  ,  2.81533   ],\n",
              "       [-2.8897111 ,  2.827007  ],\n",
              "       [-2.881186  ,  2.8162677 ],\n",
              "       [-2.890856  ,  2.8273485 ],\n",
              "       [-2.890693  ,  2.82696   ],\n",
              "       [-2.8953552 ,  2.8338215 ],\n",
              "       [-2.8867638 ,  2.8228617 ],\n",
              "       [-2.8848088 ,  2.8193283 ],\n",
              "       [-2.8969111 ,  2.835691  ],\n",
              "       [-2.8953218 ,  2.834668  ],\n",
              "       [-2.876408  ,  2.8089855 ],\n",
              "       [-2.8835135 ,  2.8195632 ],\n",
              "       [-2.895562  ,  2.8351386 ],\n",
              "       [-2.8794577 ,  2.814729  ],\n",
              "       [-2.8920403 ,  2.8309786 ],\n",
              "       [-2.889269  ,  2.8256605 ],\n",
              "       [-2.893634  ,  2.8324811 ],\n",
              "       [-2.8962011 ,  2.8350956 ],\n",
              "       [-2.893187  ,  2.8313072 ],\n",
              "       [-2.8891535 ,  2.8260818 ],\n",
              "       [-2.8769674 ,  2.8099415 ],\n",
              "       [-2.8976977 ,  2.8360312 ],\n",
              "       [-2.890101  ,  2.8287685 ],\n",
              "       [-2.8803163 ,  2.8137834 ],\n",
              "       [-2.8870592 ,  2.8247063 ],\n",
              "       [-2.8872828 ,  2.8247402 ],\n",
              "       [-2.8831298 ,  2.8177516 ],\n",
              "       [-2.8924654 ,  2.8305495 ],\n",
              "       [-2.886927  ,  2.8241413 ],\n",
              "       [-2.8805318 ,  2.8164604 ],\n",
              "       [-2.8905966 ,  2.8289506 ],\n",
              "       [-2.8829348 ,  2.81934   ],\n",
              "       [-2.9026833 ,  2.8438442 ],\n",
              "       [-2.884646  ,  2.8200054 ],\n",
              "       [-2.876572  ,  2.8099644 ],\n",
              "       [-2.8890884 ,  2.8263693 ],\n",
              "       [-2.8813565 ,  2.8164728 ],\n",
              "       [-2.8882818 ,  2.8228157 ],\n",
              "       [-2.890464  ,  2.8274968 ],\n",
              "       [-2.896978  ,  2.835901  ],\n",
              "       [-2.8963318 ,  2.8351138 ],\n",
              "       [-2.885399  ,  2.8209765 ],\n",
              "       [-2.8736331 ,  2.806888  ],\n",
              "       [-2.88898   ,  2.8259199 ],\n",
              "       [-2.8969147 ,  2.835298  ],\n",
              "       [-2.895086  ,  2.8340414 ],\n",
              "       [-2.8948977 ,  2.8335774 ],\n",
              "       [-2.882771  ,  2.8196511 ],\n",
              "       [-2.8918664 ,  2.829938  ],\n",
              "       [-2.8880699 ,  2.8245842 ],\n",
              "       [-2.8934028 ,  2.8315904 ],\n",
              "       [-2.8886907 ,  2.825563  ],\n",
              "       [-2.8854887 ,  2.8219178 ],\n",
              "       [-2.8899987 ,  2.8259947 ],\n",
              "       [-2.8793502 ,  2.8148885 ],\n",
              "       [-2.8996263 ,  2.8396122 ],\n",
              "       [-2.887046  ,  2.8241444 ],\n",
              "       [-2.8904662 ,  2.82889   ],\n",
              "       [-2.8849878 ,  2.8216965 ],\n",
              "       [-2.8768435 ,  2.811501  ],\n",
              "       [-2.8856678 ,  2.8216207 ],\n",
              "       [-2.893733  ,  2.8316505 ],\n",
              "       [-2.8905592 ,  2.828705  ],\n",
              "       [-2.8835416 ,  2.820071  ],\n",
              "       [-2.880819  ,  2.8162525 ],\n",
              "       [-2.8931909 ,  2.8314266 ],\n",
              "       [-2.8781693 ,  2.8124177 ],\n",
              "       [-2.8969855 ,  2.8358371 ],\n",
              "       [-2.8843806 ,  2.821378  ],\n",
              "       [-2.8859956 ,  2.8213694 ],\n",
              "       [-2.893341  ,  2.8314664 ],\n",
              "       [-2.8896077 ,  2.8266885 ],\n",
              "       [-2.8997378 ,  2.8397012 ],\n",
              "       [-2.8946486 ,  2.8324907 ],\n",
              "       [-2.888247  ,  2.8257744 ],\n",
              "       [-2.8935854 ,  2.8314312 ],\n",
              "       [-2.8852253 ,  2.8211489 ],\n",
              "       [-2.8845813 ,  2.8200743 ],\n",
              "       [-2.879162  ,  2.8130343 ],\n",
              "       [-2.8881974 ,  2.8258028 ],\n",
              "       [-2.8855977 ,  2.8218124 ],\n",
              "       [-2.894367  ,  2.8337777 ],\n",
              "       [-2.8918726 ,  2.8298094 ],\n",
              "       [-2.8855522 ,  2.8223228 ],\n",
              "       [-2.8729968 ,  2.8062267 ],\n",
              "       [-2.8935432 ,  2.832634  ],\n",
              "       [-2.8805587 ,  2.8157406 ],\n",
              "       [-2.879998  ,  2.8155715 ],\n",
              "       [-2.8877223 ,  2.823582  ],\n",
              "       [-2.8829994 ,  2.8170314 ],\n",
              "       [-2.8850772 ,  2.8213592 ],\n",
              "       [-2.8913221 ,  2.8272622 ],\n",
              "       [-2.8843768 ,  2.8201063 ],\n",
              "       [-2.8875432 ,  2.8242753 ],\n",
              "       [-2.8826718 ,  2.8172457 ],\n",
              "       [-2.8880095 ,  2.823835  ],\n",
              "       [-2.8962212 ,  2.8352995 ],\n",
              "       [-2.8816645 ,  2.8181753 ],\n",
              "       [-2.8938181 ,  2.8316689 ],\n",
              "       [-2.8811977 ,  2.8145857 ],\n",
              "       [-2.8957994 ,  2.8352    ],\n",
              "       [ 0.18868816, -0.16270036]], dtype=float32), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0893lJ1DgHgC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming predictions is a TensorFlow tensor containing the output\n",
        "threshold = 0.5  # You can adjust this threshold as needed\n",
        "\n",
        "# Extract the logits or probabilities from the output\n",
        "logits = predictions.logits  # Use 'logits' if available, or 'logits' could be 'scores' or other suitable name\n",
        "\n",
        "# Apply the threshold using TensorFlow's greater function\n",
        "predicted_labels = tf.cast(tf.greater(logits, threshold), tf.int64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo7NElv0hcZl",
        "outputId": "c773cf92-a007-46b6-c84d-4e08cda2057f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-2.8904889 ,  2.827261  ],\n",
              "       [-2.8766267 ,  2.8100615 ],\n",
              "       [-2.885503  ,  2.821956  ],\n",
              "       [-2.9026833 ,  2.8438442 ],\n",
              "       [-2.8899822 ,  2.826699  ],\n",
              "       [-2.8964198 ,  2.8352733 ],\n",
              "       [-2.898803  ,  2.83865   ],\n",
              "       [-2.8891773 ,  2.8264182 ],\n",
              "       [-2.8751347 ,  2.8076615 ],\n",
              "       [-2.8904862 ,  2.8290937 ],\n",
              "       [-2.8811347 ,  2.8143876 ],\n",
              "       [-2.8924742 ,  2.8285248 ],\n",
              "       [-2.8819401 ,  2.8174126 ],\n",
              "       [-2.894182  ,  2.8320987 ],\n",
              "       [-2.8779342 ,  2.812503  ],\n",
              "       [-2.8864    ,  2.8240535 ],\n",
              "       [-2.8934538 ,  2.8309734 ],\n",
              "       [-2.8851924 ,  2.8207319 ],\n",
              "       [-2.8847926 ,  2.821268  ],\n",
              "       [-2.8915598 ,  2.8276443 ],\n",
              "       [-2.8867402 ,  2.8219538 ],\n",
              "       [-2.8854513 ,  2.8216171 ],\n",
              "       [-2.8933342 ,  2.8309875 ],\n",
              "       [-2.8744612 ,  2.808836  ],\n",
              "       [-2.8953183 ,  2.8346622 ],\n",
              "       [-2.8803852 ,  2.815894  ],\n",
              "       [-2.8823717 ,  2.816961  ],\n",
              "       [-2.8835106 ,  2.8190587 ],\n",
              "       [-2.886387  ,  2.822618  ],\n",
              "       [-2.8866065 ,  2.822132  ],\n",
              "       [-2.885135  ,  2.8214178 ],\n",
              "       [-2.8894818 ,  2.8262837 ],\n",
              "       [-2.883305  ,  2.8189838 ],\n",
              "       [-2.89153   ,  2.8290384 ],\n",
              "       [-2.8801644 ,  2.8142426 ],\n",
              "       [-2.8776276 ,  2.8124063 ],\n",
              "       [-2.8884938 ,  2.8254416 ],\n",
              "       [-2.892573  ,  2.8304696 ],\n",
              "       [-2.880323  ,  2.81533   ],\n",
              "       [-2.8897111 ,  2.827007  ],\n",
              "       [-2.881186  ,  2.8162677 ],\n",
              "       [-2.890856  ,  2.8273485 ],\n",
              "       [-2.890693  ,  2.82696   ],\n",
              "       [-2.8953552 ,  2.8338215 ],\n",
              "       [-2.8867638 ,  2.8228617 ],\n",
              "       [-2.8848088 ,  2.8193283 ],\n",
              "       [-2.8969111 ,  2.835691  ],\n",
              "       [-2.8953218 ,  2.834668  ],\n",
              "       [-2.876408  ,  2.8089855 ],\n",
              "       [-2.8835135 ,  2.8195632 ],\n",
              "       [-2.895562  ,  2.8351386 ],\n",
              "       [-2.8794577 ,  2.814729  ],\n",
              "       [-2.8920403 ,  2.8309786 ],\n",
              "       [-2.889269  ,  2.8256605 ],\n",
              "       [-2.893634  ,  2.8324811 ],\n",
              "       [-2.8962011 ,  2.8350956 ],\n",
              "       [-2.893187  ,  2.8313072 ],\n",
              "       [-2.8891535 ,  2.8260818 ],\n",
              "       [-2.8769674 ,  2.8099415 ],\n",
              "       [-2.8976977 ,  2.8360312 ],\n",
              "       [-2.890101  ,  2.8287685 ],\n",
              "       [-2.8803163 ,  2.8137834 ],\n",
              "       [-2.8870592 ,  2.8247063 ],\n",
              "       [-2.8872828 ,  2.8247402 ],\n",
              "       [-2.8831298 ,  2.8177516 ],\n",
              "       [-2.8924654 ,  2.8305495 ],\n",
              "       [-2.886927  ,  2.8241413 ],\n",
              "       [-2.8805318 ,  2.8164604 ],\n",
              "       [-2.8905966 ,  2.8289506 ],\n",
              "       [-2.8829348 ,  2.81934   ],\n",
              "       [-2.9026833 ,  2.8438442 ],\n",
              "       [-2.884646  ,  2.8200054 ],\n",
              "       [-2.876572  ,  2.8099644 ],\n",
              "       [-2.8890884 ,  2.8263693 ],\n",
              "       [-2.8813565 ,  2.8164728 ],\n",
              "       [-2.8882818 ,  2.8228157 ],\n",
              "       [-2.890464  ,  2.8274968 ],\n",
              "       [-2.896978  ,  2.835901  ],\n",
              "       [-2.8963318 ,  2.8351138 ],\n",
              "       [-2.885399  ,  2.8209765 ],\n",
              "       [-2.8736331 ,  2.806888  ],\n",
              "       [-2.88898   ,  2.8259199 ],\n",
              "       [-2.8969147 ,  2.835298  ],\n",
              "       [-2.895086  ,  2.8340414 ],\n",
              "       [-2.8948977 ,  2.8335774 ],\n",
              "       [-2.882771  ,  2.8196511 ],\n",
              "       [-2.8918664 ,  2.829938  ],\n",
              "       [-2.8880699 ,  2.8245842 ],\n",
              "       [-2.8934028 ,  2.8315904 ],\n",
              "       [-2.8886907 ,  2.825563  ],\n",
              "       [-2.8854887 ,  2.8219178 ],\n",
              "       [-2.8899987 ,  2.8259947 ],\n",
              "       [-2.8793502 ,  2.8148885 ],\n",
              "       [-2.8996263 ,  2.8396122 ],\n",
              "       [-2.887046  ,  2.8241444 ],\n",
              "       [-2.8904662 ,  2.82889   ],\n",
              "       [-2.8849878 ,  2.8216965 ],\n",
              "       [-2.8768435 ,  2.811501  ],\n",
              "       [-2.8856678 ,  2.8216207 ],\n",
              "       [-2.893733  ,  2.8316505 ],\n",
              "       [-2.8905592 ,  2.828705  ],\n",
              "       [-2.8835416 ,  2.820071  ],\n",
              "       [-2.880819  ,  2.8162525 ],\n",
              "       [-2.8931909 ,  2.8314266 ],\n",
              "       [-2.8781693 ,  2.8124177 ],\n",
              "       [-2.8969855 ,  2.8358371 ],\n",
              "       [-2.8843806 ,  2.821378  ],\n",
              "       [-2.8859956 ,  2.8213694 ],\n",
              "       [-2.893341  ,  2.8314664 ],\n",
              "       [-2.8896077 ,  2.8266885 ],\n",
              "       [-2.8997378 ,  2.8397012 ],\n",
              "       [-2.8946486 ,  2.8324907 ],\n",
              "       [-2.888247  ,  2.8257744 ],\n",
              "       [-2.8935854 ,  2.8314312 ],\n",
              "       [-2.8852253 ,  2.8211489 ],\n",
              "       [-2.8845813 ,  2.8200743 ],\n",
              "       [-2.879162  ,  2.8130343 ],\n",
              "       [-2.8881974 ,  2.8258028 ],\n",
              "       [-2.8855977 ,  2.8218124 ],\n",
              "       [-2.894367  ,  2.8337777 ],\n",
              "       [-2.8918726 ,  2.8298094 ],\n",
              "       [-2.8855522 ,  2.8223228 ],\n",
              "       [-2.8729968 ,  2.8062267 ],\n",
              "       [-2.8935432 ,  2.832634  ],\n",
              "       [-2.8805587 ,  2.8157406 ],\n",
              "       [-2.879998  ,  2.8155715 ],\n",
              "       [-2.8877223 ,  2.823582  ],\n",
              "       [-2.8829994 ,  2.8170314 ],\n",
              "       [-2.8850772 ,  2.8213592 ],\n",
              "       [-2.8913221 ,  2.8272622 ],\n",
              "       [-2.8843768 ,  2.8201063 ],\n",
              "       [-2.8875432 ,  2.8242753 ],\n",
              "       [-2.8826718 ,  2.8172457 ],\n",
              "       [-2.8880095 ,  2.823835  ],\n",
              "       [-2.8962212 ,  2.8352995 ],\n",
              "       [-2.8816645 ,  2.8181753 ],\n",
              "       [-2.8938181 ,  2.8316689 ],\n",
              "       [-2.8811977 ,  2.8145857 ],\n",
              "       [-2.8957994 ,  2.8352    ],\n",
              "       [ 0.18868816, -0.16270036]], dtype=float32)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ll18Lvgg5_Y",
        "outputId": "40fc2d3c-287d-489e-dc1c-b9e9b5fbc5c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(140, 2), dtype=int64, numpy=\n",
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 0]])>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "jjVlS4wphKMA",
        "outputId": "6b09243b-7465-431d-896b-408de91609ea"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-29c84277acdc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1115, 140]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL3ymGGyb9Vr",
        "outputId": "8039449f-8a67-4cb7-f546-54b2496eacc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.5267505049705505}]\n"
          ]
        }
      ],
      "source": [
        "new_texts = [\"Hey MuhammadWe handpicked the coolest properties that tick off all your requirements and are so amazing, they will make your friends jealous. Seriously, they aren not just a place to live, it is a whole vibe, and you will make memories that will last a lifetime!\"]\n",
        "predictions = pipeline(new_texts)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aUU9ksPcPoc",
        "outputId": "6f6dc66f-22d9-4cdb-bfbe-1dbf3ced1f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.5245733261108398}]\n"
          ]
        }
      ],
      "source": [
        "new_texts = [\"hi good morning today is meeting with client\"]\n",
        "predictions = pipeline(new_texts)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "0wRj01vdU5th",
        "outputId": "82ec1973-345e-40c1-ebfd-5397bb060b47"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e99a2b14a678>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model with training_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     trainer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n\u001b[0m\u001b[1;32m      4\u001b[0m                           \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           metrics=['accuracy'])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;31m# This argument got renamed, we need to support both versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"steps_per_execution\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m             super().compile(\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_validate_compile\u001b[0;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[1;32m   3534\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_created_in_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3536\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   3537\u001b[0m                         \u001b[0;34mf\"Variable ({v}) was not created in the distribution \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m                         \u001b[0;34mf\"strategy scope of ({strategy}). It is most likely \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable (<tf.Variable 'tf_distil_bert_for_sequence_classification_1/distilbert/embeddings/word_embeddings/weight:0' shape=(30522, 768) dtype=float32, numpy=\narray([[-0.01664949, -0.06661227, -0.01632868, ..., -0.01999032,\n        -0.05139988, -0.0263568 ],\n       [-0.01319846, -0.06733431, -0.01605646, ..., -0.0226614 ,\n        -0.05537301, -0.02600443],\n       [-0.01759106, -0.07094341, -0.01443494, ..., -0.02457913,\n        -0.05956192, -0.0231829 ],\n       ...,\n       [-0.0231029 , -0.05878259, -0.01048967, ..., -0.01945743,\n        -0.02615411, -0.02118432],\n       [-0.0490171 , -0.05614787, -0.00465348, ..., -0.01065376,\n        -0.01797333, -0.02187675],\n       [-0.00646111, -0.0914881 , -0.00254872, ..., -0.01505679,\n        -0.05040044,  0.04597744]], dtype=float32)>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy object at 0x7b49e48a7760>). It is most likely because some layers, model, or optimizer was being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\nwith strategy.scope():\n  model=_create_model()\n  model.compile(...)"
          ]
        }
      ],
      "source": [
        "# Train the model with training_args\n",
        "with training_args.strategy.scope():\n",
        "    trainer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n",
        "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                          metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "wQhWcEavT6H2",
        "outputId": "7cf7ac2f-8f66-4874-91f0-45a2fb45933b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d59fed3b5fc1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     trainer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n\u001b[1;32m      4\u001b[0m                           \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           metrics=['accuracy'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_args' is not defined"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "with training_args.strategy.scope():\n",
        "    trainer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=training_args.learning_rate),\n",
        "                          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                          metrics=['accuracy'])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "YkMXmNc6xRUM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}